{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb60648",
   "metadata": {},
   "source": [
    "# Observations, data acquisition, data analysis \n",
    "## High-contrast imaging\n",
    "### Author\n",
    "D. SÃ©gransan\n",
    "### Date\n",
    "May 28, 2021\n",
    "### Goals\n",
    "Here you will study and reduce the high contrat images taken on two multiple stars, namely Gl909 and Gl494 observed at both the Canada-France-Hawaii telescope with the PUEO adaptive optics instrument  (Gl909 & Gl494) and with the NIRC2 instrument at KECK (Gl909).<br>\n",
    "For each instrument, you will : <br>\n",
    " - Describe the observing strategy <br>\n",
    " - Study and reduce the calibration files to obtain the detector gain map and badpixel map <br>\n",
    " - Process the science frames to obtain : <br>\n",
    "     - a cube of **clean** images <br>\n",
    "     - a single **high signal to noise** image<br>\n",
    " - Derive the binary star parameters (separation, position angle and flux ratio). <br>\n",
    "\n",
    "\n",
    "### Requirements\n",
    "Python 3 with numpy, matplotib and astropy.\n",
    "jupyter or jupyter-lab is recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e0945",
   "metadata": {},
   "source": [
    "# STEP 1 - Download files  GJ909A\n",
    "You can retrieve the the three sets of observations at : <br>\n",
    "https://drive.switch.ch/index.php/s/G5qxW8xUrW211rn for GJ909A (PUEO@CFHT) <br>\n",
    "- Dark File : '643879o.fits'\n",
    "- Dome Flats : '6479[57-62]f.fits'\n",
    "- Science Frames : '64792[1-5]o.fits'\n",
    "\n",
    "\n",
    "Information about the PUEO detector can be found here : \n",
    "https://www.cfht.hawaii.edu/Instruments/Detectors/IR/KIR/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7809c6",
   "metadata": {},
   "source": [
    "#  STEP 2 - QuickLook at the images and observing strategy \n",
    "## Use of DS9 to highlight features in the raw images\n",
    "Load the images into DS9. <br>\n",
    "From the top menu, choose :\n",
    " - **File** and select ***Display Header***. Describe and categorize the image you are dealing, *ie.* type of image, format, filter (and observing wavelength), exposure time, date, MJD, Time (UT) and Airmass.<br> \n",
    " - **Scale** and select ***scale parameters***. Set the min/max values according to the histogram of the image flux. Write down the filename you are looking at and the the values you have choosen. Change scales to ***log, lin, sqrt***. Make screenshots and attach them to the notebook and describe what you are looking at.<br>\n",
    " - **Color** and select, ***grey, heat, cool, i8***. You can also ***invert*** each of the color map. Same a above, make a screenshot and provide a very short description.<br>\n",
    " - **Analysis** and select,   ***contours*** and ***grid*** to improve the localisation of the features in the images. Same a above, make a screenshot and provide a very short description.<br>\n",
    " - **Frame** and select,   ***cube*** and browse trough the individual frames of the image cube of the *f.fits and *o.fits files. Describe what you are looking at. Pay a special attention to the *o.fits files<br>\n",
    "\n",
    "Describe the observing strategy that was chosen by the observer and  make an ***educated guess*** on the use you will make of these different files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49e450",
   "metadata": {},
   "source": [
    "# STEP 3 -  Gain map & Bad pixel map  from the Flats\n",
    "You should have noticed from the image quicklook analysis that the detector has a significant number of bad pixels. Such pixels should be identified and flagged in a ***bad pixel map***. In addition, a ***detector gain map*** should be created to take into account the pixels' response that varies from pixel to pixel. These two steps are essential and must be done with care before conducting any *advanced* image analysis. Indeed, residual *bad pixels* our an incorrect estimate of the pixels' response could lead to serious biases in the determination of the position (astrometry) and flux (photometry) of the target(s) that  are  being  studied. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868979c5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74782e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,os,os.path\n",
    "from astropy.io import fits\n",
    "from astropy.stats import mad_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449c6e4",
   "metadata": {},
   "source": [
    "#### This section of the practical makes use of the following functions/commands :\n",
    "***Mandatory :*** <br>\n",
    "hdul   = fits.open()<br>\n",
    "hdul[0].header<br>\n",
    "hdul[0].data<br>\n",
    "hdul.close()<br>\n",
    "<br>\n",
    "fig,ax=plt.subplots()<br>\n",
    "ax.hist()<br>\n",
    "ax.imshow()<br>\n",
    "ax.text()<br>\n",
    "plt.savefig()<br>\n",
    "<br>\n",
    "image.flatten()<br>\n",
    "np.mean()<br>\n",
    "np.median()<br>\n",
    "np.std()<br>\n",
    "np.percentile()<br>\n",
    "mad_std()<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f32c3",
   "metadata": {},
   "source": [
    "## Dome Flats Statistics\n",
    "Sequentially load the dome flats and collapse them along the z-axis by taking the \n",
    "- median\n",
    "- mean\n",
    "\n",
    "Store the values in two image cubes **flatMed** and **flatMean** of size **(Nflats,Nx,Ny)** where Nflats is the number falt fits-files taken with different exposure time, (Nx,Ny) is the size if the image.\n",
    "Store also the values of the exposure time in an 1D array **flatExpTime** of size **(Nflats)**.\n",
    "\n",
    "Estimate, for each pixel the flux disperion  along the z-axis using the :\n",
    "- standard deviation (std)\n",
    "- median absolute deviation (mad)\n",
    "\n",
    "Store the values in two image cubes **flatStd** and **flatMad** of size **(Nflats,Nx,Ny)** \n",
    "\n",
    "Explain why the **median** and the **mad** are prefered - in some cases - to the **mean** and the **standard deviation** to estimate the first two moments of a distribution.\n",
    "\n",
    "In the following part, you'll be working with flat images collapsed on the z-axis using the **median** and the **mad**.\n",
    "\n",
    "Sort the collapsed dome flats according to their exposure time, flatten the 2D array and display their flux histograms. <br><br>\n",
    "List the following **percentiles** for each of the flat **(0.5\\%, 2.5\\%, 5\\%,25\\% 50\\%, 25\\%, 5\\%, 2.5\\%,0.5\\%)**<br>\n",
    "<br>\n",
    "Comment<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a76a8a",
   "metadata": {},
   "source": [
    "## Gain map & Bad pixel map\n",
    "You'll be using the **flatMed**  and **flatMad** cubes generated before to create the detector's **bad pixel map** and **gain map**.\n",
    "To do so, you'll estimate the response of each pixel to linear increase in flux by performing a linear regression along the  z-axis (exposure time), *where*  : <br>\n",
    "- t = flatExpTime     : size (Nflats)\n",
    "- y = flatMed[:,i,j]  :  size (Nflats)\n",
    "- yerr :      size (Nflats)\n",
    "\n",
    "The errors on ***y*** can be estimated using :\n",
    "- the detector readout value of sigDet = 5AU for each exposure \n",
    "- the pixel photon noise \n",
    "\n",
    "***Beware*** that we have already averaged the original cubes. It does impact the estimate of both the photon and detector noise. By which amount ?<br>\n",
    "*Hint:* How many frames are present in the original *f.fits cubes ?\n",
    "\n",
    "Provide here an estimate of yerr.\n",
    "\n",
    "Check your results for several pixels of coordinates (i,j):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a387249",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j=200,150\n",
    "for k in range(0,Nflats):\n",
    "    print('%4.0f   %8.1f  %6.1f  %6.1f'%(flatExpTime[k],flatMedCube[k,i,j],\n",
    "                                         flatMadCube[k,i,j],yerr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842c9c6",
   "metadata": {},
   "source": [
    "### Linear regression - a short recap\n",
    "Let's consider a set of *N* observations $\\boldsymbol{y}$ with uncorrelated error bars $\\boldsymbol{\\sigma}$ which can modeled with a linear model composed of M parameteres such that : <br>\n",
    "$\\boldsymbol{f} = \\boldsymbol{X}.\\boldsymbol{a}$  where $\\boldsymbol{X}$ is a matrix of size *(N,M)* and  $\\boldsymbol{a}$ a vector of size *M*.<br><br>\n",
    "Let's make the following change of variables  $\\boldsymbol{b}=\\boldsymbol{y}/\\boldsymbol{\\sigma}$,  $\\boldsymbol{A}=\\boldsymbol{X}/\\boldsymbol{\\sigma}$ and  write the\n",
    "*chi-square* as $\\chi^2 = (\\boldsymbol{b}-\\boldsymbol{A}.\\boldsymbol{a})^T.(\\boldsymbol{b}-\\boldsymbol{A}.\\boldsymbol{a})$.  Here  $\\boldsymbol{A}$ is called the ***designed matrix***.<br>\n",
    "\n",
    "Minimizing the $\\chi^2$ is easily done and results in a set of M equations with M unkwnowns called the  ***normal equation*** written : <br>\n",
    "$\\boldsymbol{A}^T.\\boldsymbol{b}=\\boldsymbol{A}^T.\\boldsymbol{A}.\\boldsymbol{a}$<br>\n",
    "\n",
    "Solving the normal equation  for $\\boldsymbol{a}$ leads to $\\boldsymbol{a}=(\\boldsymbol{A}^T.\\boldsymbol{A})^{-1} . \\boldsymbol{A}^T.\\boldsymbol{b}$ where $\\boldsymbol{C}= (\\boldsymbol{A}^T.\\boldsymbol{A})^{-1}$ is called the ***covariance matrix***.<br>\n",
    "\n",
    "The diagonal elements of  $\\boldsymbol{A}$ are the variances of the adjusted parameters  $\\boldsymbol{a}$  and\n",
    "correspond to the squared uncertainties (or squared standard deviation) of the adjusted parameters $\\boldsymbol{a}$, *ie.*  $\\sigma^2(a_i) = C_{i,i}$. The off-diagonal elements of $C_{j,k}, j \\neq k$ are the covariances between $a_j$ and $a_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c470c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leastsq(A,b):\n",
    "    #solve normal equation  a = C.At.b\n",
    "    alpha= np.dot(A.T, A)\n",
    "    beta = np.dot(A.T, b)\n",
    "    C = np.linalg.inv(alpha)\n",
    "    a = np.dot(C,beta)\n",
    "    r = b-np.dot(A,a)\n",
    "    chi2 = np.dot(r.T,r)\n",
    "    \n",
    "    return  a,C,chi2\n",
    "\n",
    "def fitStraightLine(y, yerr, texp):\n",
    "    #create designed Matrix of a straight line model\n",
    "    #and solve the normal equation for a \n",
    "    X=np.vstack([texp, np.ones(len(texp))]).T\n",
    "    b=y/yerr\n",
    "    A=X/yerr[:,np.newaxis]\n",
    "    return leastsq(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08873f24",
   "metadata": {},
   "source": [
    "#### Computing the Gain Map\n",
    "You can either use the  ***fitStraightLine*** or your favourite python package to perform the linear regression.\n",
    "\n",
    "You will create here 3 maps of size (Nx,Ny) which contain:\n",
    "- the *reduced chi-square* values\n",
    "- the fitted slope values\n",
    "- the errors on the fitted slope\n",
    "- the gain map\n",
    "\n",
    "***Remark :*** The *gain map* is estimated by dividing the *slope map*  by its median value.\n",
    "\n",
    "Display each of the map (imshow) with an adequate color map/scale\n",
    "\n",
    "Flatten each of the 2D array and display their histograms. \n",
    "\n",
    "List the following percentiles for each map (0.5%, 2.5%, 5%,25% 50%, 25%, 5%, 2.5%,0.5%)\n",
    "\n",
    "**Comment your results :**\n",
    "\n",
    "**More advanced Question :** How would you estimate if the detector has a non-linear response ? How would you model it and correct for it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ffe964",
   "metadata": {},
   "source": [
    "#### Creating the  bad pixel Map\n",
    "Pixels are tagged as *bad* when their *gain* lies outside a given initerval. \n",
    "- Give the interval for which pixels can be considered as bad.\n",
    "- Provide possible additional criteria to flag bad pixels.\n",
    "- Create several bad pixel maps, display and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1cbc4c",
   "metadata": {},
   "source": [
    "# STEP 4 -  Load and calibrate the science images\n",
    "\n",
    "Now that you have  generated the detector gain map and a bad pixel map, you can create a  fully calibrated image\n",
    "imc=(im-background)/gain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286862c",
   "metadata": {},
   "source": [
    "# STEP 5 -  Separation, orientation  and flux ratio of the binary star.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99799b",
   "metadata": {},
   "source": [
    "# STEP 6 -  Combining the 5 sequences of images into a  single high signal to noise image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f54c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
